# This is a basic workflow to help you get started with Actions

name: Deploy notebook to databrick

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the "main" branch
  push:
    branches: [ "dev" ]

  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: set up python
        uses: actions/setup-python@v4
        with:
          python-version: '3.8'

      - name: Install Databrick CLI
        run: |
          python -m pip install --upgrade pip
          pip install databricks-cli
          databricks -v

      - name: Configure databrick cli
        env:
          DATABRICKS_HOST: ${{secrets.DATABRICKS_HOST}}
          DATABRICKS_CLIENT_ID: ${{secrets.DATABRICKS_CLIENT_ID}}
          DATABRICKS_CLIENT_SECRET: ${{secrets.DATABRICKS_CLIENT_SECRET}}
        run: |
          export DATABRICKS_HOST=$"{secrets.DATABRICKS_HOST}"
          export DATABRICKS_CLIENT_ID=$"{secrets.DATABRICKS_CLIENT_ID}"
          export DATABRICKS_CLIENT_SECRET=$"{secrets.DATABRICKS_CLIENT_SECRET}"

      - name: deploy code to databrick workspace
        run: |
          databricks workspace import_dir ./ /workspace

      # - name: Create Databricks Job
      #   run: |
      #     databricks jobs create --json-file job_definition.json

      # - name: Run Databricks Job
      #   run: |
      #     databricks jobs run-now --job-id JOB_ID

